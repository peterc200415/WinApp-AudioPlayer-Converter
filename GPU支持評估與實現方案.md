# GPU å¹³å°æ”¯æŒè©•ä¼°èˆ‡å¯¦ç¾æ–¹æ¡ˆ

## ğŸ“Š ç•¶å‰å¯¦ç¾ç‹€æ…‹

### ç¾æœ‰æ”¯æŒ
- âœ… **NVIDIA GPU (CUDA)**ï¼šå·²å¯¦ç¾ï¼Œé€šé `torch.cuda.is_available()` æª¢æ¸¬
- âœ… **CPU**ï¼šå·²å¯¦ç¾ï¼Œä½œç‚º fallback
- âŒ **AMD GPU (ROCm)**ï¼šæœªå¯¦ç¾
- âŒ **Intel GPU**ï¼šæœªå¯¦ç¾

### ç•¶å‰ä»£ç¢¼
```python
# src/core/transcriber.py (ç¬¬ 39-55 è¡Œ)
def _get_device(self, device_preference: str = "auto") -> str:
    if device_preference == "cuda" and torch.cuda.is_available():
        return "cuda"
    elif device_preference == "cpu":
        return "cpu"
    else:
        return "cuda" if torch.cuda.is_available() else "cpu"
```

---

## ğŸ¯ å„å¹³å°å¯¦ç¾é›£åº¦è©•ä¼°

### 1. NVIDIA GPU (CUDA) â­ **ç°¡å–®** âœ… å·²å®Œæˆ

**é›£åº¦**ï¼šä½  
**ç¾ç‹€**ï¼šå·²å®Œç¾æ”¯æŒ

**å„ªå‹¢**ï¼š
- Whisper åŸç”Ÿæ”¯æŒ PyTorch + CUDA
- é©…å‹•ç©©å®šï¼Œæ–‡æª”å®Œå–„
- æ€§èƒ½æœ€ä½³ï¼ˆ10-50x åŠ é€Ÿ vs CPUï¼‰

**å¯¦ç¾æ–¹å¼**ï¼š
```python
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("base", device=device)
```

---

### 2. AMD GPU (ROCm) â­â­ **ä¸­ç­‰é›£åº¦**

**é›£åº¦**ï¼šä¸­  
**ç¾ç‹€**ï¼šéœ€è¦é¡å¤–é…ç½®

**æŒ‘æˆ°**ï¼š
1. **é©…å‹•å®‰è£è¤‡é›œ**ï¼šROCm ç‰ˆæœ¬èˆ‡ GPU å‹è™Ÿéœ€åŒ¹é…
2. **PyTorch æ”¯æ´**ï¼šéœ€è¦å®‰è£ `torch-rocm` ç‰ˆæœ¬ï¼ˆéå®˜æ–¹é ç·¨è­¯ç‰ˆæœ¬ï¼‰
3. **ç©©å®šæ€§**ï¼šæŸäº›æ“ä½œå¯èƒ½æœ‰ bug æˆ–æ€§èƒ½å•é¡Œ

**å¯¦ç¾æ–¹å¼**ï¼š

#### æ–¹æ¡ˆ Aï¼šPyTorch ROCmï¼ˆæ¨è–¦ï¼‰
```python
# éœ€è¦å®‰è£: pip install torch --index-url https://download.pytorch.org/whl/rocm5.6
if torch.version.cuda is None and hasattr(torch.version, 'hip'):
    device = "cuda"  # ROCm ä½¿ç”¨ "cuda" ä½œç‚ºè¨­å‚™åç¨±
```

#### æ–¹æ¡ˆ Bï¼šONNX Runtime + ROCm
```python
import onnxruntime as ort
sess_options = ort.SessionOptions()
provider_options = [{'device_type': 'hip'}]  # ROCm backend
```

**å·¥ä½œé‡**ï¼š2-4 å°æ™‚
- æª¢æ¸¬ ROCm ç’°å¢ƒ
- å®‰è£æŒ‡å°æ–‡æª”
- æ¸¬è©¦èˆ‡é©—è­‰

---

### 3. Intel GPU â­â­â­ **è¼ƒé«˜é›£åº¦**

**é›£åº¦**ï¼šä¸­é«˜  
**ç¾ç‹€**ï¼šéœ€è¦æ¨¡å‹è½‰æ›

**æŒ‘æˆ°**ï¼š
1. **æ¨¡å‹æ ¼å¼è½‰æ›**ï¼šéœ€è¦å°‡ Whisper è½‰ç‚º ONNX æˆ– OpenVINO IR
2. **API å·®ç•°**ï¼šä½¿ç”¨ OpenVINO è€Œéç›´æ¥ PyTorch
3. **æ€§èƒ½é™åˆ¶**ï¼šå°å¤§å‹æ¨¡å‹å¯èƒ½ä¸å¦‚ NVIDIA/AMD

**å¯¦ç¾æ–¹å¼**ï¼š

#### æ–¹æ¡ˆ Aï¼šOpenVINOï¼ˆæ¨è–¦ Intel Arc GPUï¼‰
```python
# 1. è½‰æ›æ¨¡å‹ç‚º ONNX
# 2. ä½¿ç”¨ OpenVINO Runtime
from openvino.runtime import Core

core = Core()
model = core.read_model("whisper.onnx")
compiled_model = core.compile_model(model, "GPU")  # Intel GPU
```

#### æ–¹æ¡ˆ Bï¼šIntel Extension for PyTorch (IPEX)
```python
import intel_extension_for_pytorch as ipex
model = whisper.load_model("base")
model = ipex.optimize(model)
# ä½¿ç”¨ xpu è¨­å‚™
```

**å·¥ä½œé‡**ï¼š4-8 å°æ™‚
- æ¨¡å‹è½‰æ›è…³æœ¬
- OpenVINO æ•´åˆ
- Intel GPU æª¢æ¸¬
- æ€§èƒ½å„ªåŒ–

---

## ğŸ’¡ æ¨è–¦å¯¦ç¾ç­–ç•¥

### éšæ®µä¸€ï¼šå¢å¼·ç¾æœ‰å¯¦ç¾ï¼ˆ1-2 å°æ™‚ï¼‰

**ç›®æ¨™**ï¼šæ”¹é€²è¨­å‚™æª¢æ¸¬ï¼Œæ”¯æ´å¤š GPU é¸æ“‡

**æ”¹é€²**ï¼š
1. æ·»åŠ  GPU è³‡è¨Šæª¢æ¸¬ï¼ˆå‹è™Ÿã€è¨˜æ†¶é«”ï¼‰
2. æ”¯æ´æ‰‹å‹•é¸æ“‡ GPUï¼ˆå¤š GPU ç’°å¢ƒï¼‰
3. æ›´è©³ç´°çš„éŒ¯èª¤æç¤º

**å„ªé»**ï¼š
- ä¿æŒç°¡å–®ï¼Œä¸å¢åŠ è¤‡é›œåº¦
- æ”¹å–„ NVIDIA GPU ä½¿ç”¨é«”é©—
- ç‚ºæœªä¾†æ“´å±•æ‰“ä¸‹åŸºç¤

---

### éšæ®µäºŒï¼šæ·»åŠ  AMD ROCm æ”¯æŒï¼ˆå¯é¸ï¼Œ2-4 å°æ™‚ï¼‰

**å‰ææ¢ä»¶**ï¼š
- ç”¨æˆ¶å·²å®‰è£ ROCm é©…å‹•
- ä½¿ç”¨ PyTorch ROCm ç‰ˆæœ¬

**å¯¦ç¾**ï¼š
```python
def _detect_amd_gpu(self) -> bool:
    """æª¢æ¸¬ AMD GPU (ROCm)"""
    try:
        # æª¢æŸ¥ ROCm ç’°å¢ƒ
        if hasattr(torch.version, 'hip') and torch.version.hip:
            return True
        # æˆ–æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        import os
        if 'ROCM_HOME' in os.environ:
            return True
    except:
        pass
    return False
```

---

### éšæ®µä¸‰ï¼šæ·»åŠ  Intel GPU æ”¯æŒï¼ˆå¯é¸ï¼Œ4-8 å°æ™‚ï¼‰

**å‰ææ¢ä»¶**ï¼š
- æ¨¡å‹è½‰æ›ç‚º ONNX
- å®‰è£ OpenVINO Toolkit

**å¯¦ç¾**ï¼š
- å‰µå»ºæ¨¡å‹è½‰æ›å·¥å…·
- æ•´åˆ OpenVINO Runtime
- æ·»åŠ  Intel GPU æª¢æ¸¬

---

## ğŸ“‹ å»ºè­°çš„æœ€çµ‚å¯¦ç¾

### æ¨è–¦æ–¹æ¡ˆï¼šå„ªå…ˆæ”¯æ´ NVIDIA + å®Œå–„çš„ CPU Fallback

**åŸå› **ï¼š
1. **è¦†è“‹é¢å»£**ï¼šNVIDIA GPU ä½”æ“šå¸‚å ´ä¸»å°åœ°ä½ï¼ˆç´„ 80%+ï¼‰
2. **ç©©å®šæ€§é«˜**ï¼šCUDA æ”¯æŒæœ€æˆç†Ÿ
3. **é–‹ç™¼æˆæœ¬ä½**ï¼šç•¶å‰å·²å¯¦ç¾ï¼Œåªéœ€å¢å¼·
4. **ç”¨æˆ¶é«”é©—**ï¼šçµ•å¤§å¤šæ•¸ç”¨æˆ¶å¯ç«‹å³å—ç›Š

### å®Œæ•´æ–¹æ¡ˆï¼ˆé€²éšï¼‰

å¦‚æœæœªä¾†è¦å…¨é¢æ”¯æ´ï¼Œå»ºè­°æ¡ç”¨**ç¡¬é«”æŠ½è±¡å±¤**è¨­è¨ˆï¼š

```
Transcriber (çµ±ä¸€æ¥å£)
    â”œâ”€ CUDABackend (NVIDIA)
    â”œâ”€ ROCmBackend (AMD)
    â”œâ”€ OpenVINOBackend (Intel)
    â””â”€ CPUBackend (Fallback)
```

**å¥½è™•**ï¼š
- æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œæ˜“æ–¼æ“´å±•
- æ¯ç¨®å¾Œç«¯ç¨ç«‹å¯¦ç¾å’Œæ¸¬è©¦
- å¯é¸å®‰è£ï¼ˆç”¨æˆ¶åªå®‰è£éœ€è¦çš„ï¼‰

---

## ğŸ”§ ç«‹å³æ”¹é€²å»ºè­°

### æ”¹é€² 1ï¼šå¢å¼·è¨­å‚™æª¢æ¸¬ï¼ˆ30 åˆ†é˜ï¼‰

æ·»åŠ  GPU è³‡è¨Šé¡¯ç¤ºï¼Œå¹«åŠ©ç”¨æˆ¶äº†è§£ç¡¬é«”ç‹€æ…‹ï¼š

```python
def get_device_info(self) -> Dict[str, Any]:
    """ç²å–è¨­å‚™è©³ç´°è³‡è¨Š"""
    info = {
        "available_devices": [],
        "recommended_device": "cpu"
    }
    
    # æª¢æ¸¬ NVIDIA GPU
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            info["available_devices"].append({
                "type": "NVIDIA CUDA",
                "name": gpu_name,
                "memory_gb": f"{gpu_memory:.1f}",
                "device_id": f"cuda:{i}"
            })
            info["recommended_device"] = f"cuda:{i}" if i == 0 else info["recommended_device"]
    
    # æª¢æ¸¬ CPU
    import psutil
    cpu_count = psutil.cpu_count()
    info["available_devices"].append({
        "type": "CPU",
        "name": f"CPU ({cpu_count} cores)",
        "device_id": "cpu"
    })
    
    return info
```

### æ”¹é€² 2ï¼šé…ç½®é¸é …å¢å¼·ï¼ˆ15 åˆ†é˜ï¼‰

åœ¨é…ç½®ä¸­æ·»åŠ æ›´è©³ç´°çš„è¨­å‚™é¸é …ï¼š

```json
{
    "device": "auto",  // "auto", "cuda", "cuda:0", "cpu"
    "device_preference": {
        "primary": "cuda",
        "fallback": "cpu"
    }
}
```

---

## ğŸ“Š å·¥ä½œé‡ç¸½çµ

| ä»»å‹™ | é›£åº¦ | å·¥ä½œé‡ | å„ªå…ˆç´š | åƒ¹å€¼ |
|------|------|--------|--------|------|
| å¢å¼· NVIDIA GPU æ”¯æŒ | â­ | 1-2å°æ™‚ | é«˜ | é«˜ |
| æ·»åŠ  AMD ROCm æ”¯æŒ | â­â­ | 2-4å°æ™‚ | ä¸­ | ä¸­ |
| æ·»åŠ  Intel GPU æ”¯æŒ | â­â­â­ | 4-8å°æ™‚ | ä½ | ä½ |
| ç¡¬é«”æŠ½è±¡å±¤é‡æ§‹ | â­â­â­â­ | 8-16å°æ™‚ | ä½ | é«˜ï¼ˆé•·æœŸï¼‰ |

---

## âœ… çµè«–

**ç•¶å‰å»ºè­°**ï¼š
- âœ… **NVIDIA GPU**ï¼šå·²å¯¦ç¾ï¼Œåªéœ€å¢å¼·
- âš ï¸ **AMD GPU**ï¼šå¯é¸ï¼Œéœ€è¦ç”¨æˆ¶å®‰è£ ROCm
- âš ï¸ **Intel GPU**ï¼šå¯é¸ï¼Œéœ€è¦æ¨¡å‹è½‰æ›

**å¯¦ç¾é›£åº¦æ’åº**ï¼š
1. NVIDIA (CUDA) - å·²å®Œæˆ âœ…
2. AMD (ROCm) - ä¸­ç­‰ âš ï¸
3. Intel (OpenVINO) - è¼ƒé«˜ âš ï¸

**ç¸½é«”è©•ä¼°**ï¼š
- **ä¸å›°é›£**ï¼Œä½†éœ€è¦é¡å¤–é…ç½®å’Œæ¸¬è©¦
- å»ºè­°å…ˆå®Œå–„ NVIDIA æ”¯æŒï¼Œå†é€æ­¥æ“´å±•
- å¤§å¤šæ•¸ç”¨æˆ¶ä½¿ç”¨ NVIDIA GPUï¼Œå„ªå…ˆæ”¯æ´æœ€æœ‰åƒ¹å€¼
